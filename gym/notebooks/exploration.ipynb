{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Gymnasium + MuJoCo Exploration\n",
                "\n",
                "This notebook provides an interactive environment for exploring Gymnasium MuJoCo environments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import gymnasium as gym\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from IPython.display import HTML\n",
                "from matplotlib import animation\n",
                "from typing import List, Tuple, cast\n",
                "\n",
                "from src.utils import print_env_info, create_env"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Overview"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create an environment\n",
                "# Explicitly typing the environment helps with IDE datatips\n",
                "env: gym.Env = create_env(\"HalfCheetah-v5\", render_mode=\"rgb_array\")\n",
                "print_env_info(env)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Visualize Random Actions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Collect frames from a random episode\n",
                "frames = []\n",
                "obs, info = env.reset()\n",
                "\n",
                "for _ in range(200):\n",
                "    frames.append(env.render())\n",
                "    action = env.action_space.sample()\n",
                "    obs, reward, terminated, truncated, info = env.step(action)\n",
                "    if terminated or truncated:\n",
                "        break\n",
                "\n",
                "env.close()\n",
                "print(f\"Collected {len(frames)} frames\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create animation\n",
                "fig, ax = plt.subplots(figsize=(8, 6))\n",
                "ax.axis('off')\n",
                "im = ax.imshow(frames[0])\n",
                "\n",
                "def animate(i):\n",
                "    im.set_array(frames[i])\n",
                "    return [im]\n",
                "\n",
                "anim = animation.FuncAnimation(\n",
                "    fig, animate, frames=len(frames), interval=33, blit=True\n",
                ")\n",
                "plt.close()\n",
                "\n",
                "HTML(anim.to_jshtml())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Explore Different Environments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List of MuJoCo environments to explore\n",
                "mujoco_envs = [\n",
                "    \"InvertedPendulum-v5\",\n",
                "    \"HalfCheetah-v5\",\n",
                "    \"Hopper-v5\",\n",
                "    \"Walker2d-v5\",\n",
                "    \"Ant-v5\",\n",
                "    \"Humanoid-v5\",\n",
                "]\n",
                "\n",
                "# Compare observation and action space sizes\n",
                "print(f\"{'Environment':<30} {'Obs Shape':<15} {'Action Shape':<15}\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for env_id in mujoco_envs:\n",
                "    # Type hint for the temporary environment\n",
                "    env: gym.Env = gym.make(env_id)\n",
                "    print(f\"{env_id:<30} {str(env.observation_space.shape):<15} {str(env.action_space.shape):<15}\")\n",
                "    env.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Analyze Reward Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run multiple episodes and plot reward distribution\n",
                "env: gym.Env = create_env(\"HalfCheetah-v5\")\n",
                "\n",
                "n_episodes = 10\n",
                "episode_rewards = []\n",
                "\n",
                "for ep in range(n_episodes):\n",
                "    obs, info = env.reset()\n",
                "    total_reward = 0\n",
                "    done = False\n",
                "    \n",
                "    while not done:\n",
                "        action = env.action_space.sample()\n",
                "        obs, reward, terminated, truncated, info = env.step(action)\n",
                "        total_reward += reward\n",
                "        done = terminated or truncated\n",
                "    \n",
                "    episode_rewards.append(total_reward)\n",
                "\n",
                "env.close()\n",
                "\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.bar(range(n_episodes), episode_rewards)\n",
                "plt.xlabel('Episode')\n",
                "plt.ylabel('Total Reward')\n",
                "plt.title('Episode Rewards (Random Policy)')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.hist(episode_rewards, bins=10, edgecolor='black')\n",
                "plt.xlabel('Total Reward')\n",
                "plt.ylabel('Count')\n",
                "plt.title('Reward Distribution')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"Mean: {np.mean(episode_rewards):.2f}, Std: {np.std(episode_rewards):.2f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}